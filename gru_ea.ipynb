{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3f0140",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 使用geatpy优化GRU定位模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217aa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geatpy as ea\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN, GRU\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a920f",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e844fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    dv = df.values\n",
    "    X = dv[:, 1:-2]\n",
    "    Y = dv[:, -2:]\n",
    "    return X[:, :, np.newaxis], Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e81508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data('./dataset/location_data.csv')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabd71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)  # 训练测试划分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c161f",
   "metadata": {},
   "source": [
    "## 定义GRU模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd64f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFID_GRU():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=100, batch_input_shape=(None, 100, 1)))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='mse', \n",
    "                  metrics=['mae'])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ce891",
   "metadata": {},
   "source": [
    "## 训练模型查看测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef47bae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-25 00:00:14.966539: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-25 00:00:15.116032: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-25 00:00:15.140292: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 65ms/step - loss: 35.7170 - mae: 5.2448\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 21.8936 - mae: 3.8906\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 13.7486 - mae: 3.0586\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 9.3590 - mae: 2.5872\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 7.3383 - mae: 2.3267\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 6.9608 - mae: 2.2746\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 6.7455 - mae: 2.2246\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 6.3755 - mae: 2.1565\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 6.0433 - mae: 2.0902\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 5.6978 - mae: 2.0288\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 5.4122 - mae: 1.9676\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 5.0655 - mae: 1.8897\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 4.6525 - mae: 1.7784\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 4.3578 - mae: 1.6764\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 4.0329 - mae: 1.5889\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 3.9083 - mae: 1.5548\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 3.6632 - mae: 1.4960\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 3.4633 - mae: 1.4551\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 3.2272 - mae: 1.4014\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 3.0095 - mae: 1.3603\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 2.7852 - mae: 1.3187\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2.6215 - mae: 1.2882\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2.3363 - mae: 1.2073\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 2.1068 - mae: 1.1386\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.8660 - mae: 1.0809\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.6777 - mae: 1.0012\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.4649 - mae: 0.9295\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.3756 - mae: 0.9019\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.4068 - mae: 0.9089\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.1832 - mae: 0.8383\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.1632 - mae: 0.8217\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 1.0690 - mae: 0.7750\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.9828 - mae: 0.7508\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.9151 - mae: 0.7158\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.8802 - mae: 0.6941\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.8523 - mae: 0.6763\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.7719 - mae: 0.6590\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.6738 - mae: 0.6022\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.6636 - mae: 0.6113\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.6514 - mae: 0.5918\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.6047 - mae: 0.5634\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.5912 - mae: 0.5491\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.6028 - mae: 0.5537\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.5135 - mae: 0.5292\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.5030 - mae: 0.5120\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.5014 - mae: 0.5192\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.4822 - mae: 0.4989\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4883 - mae: 0.4938\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4451 - mae: 0.4887\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.4428 - mae: 0.4787\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.4065 - mae: 0.4629\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3805 - mae: 0.4470\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3624 - mae: 0.4364\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3520 - mae: 0.4311\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3422 - mae: 0.4207\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3401 - mae: 0.4151\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3341 - mae: 0.4218\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3227 - mae: 0.4086\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3372 - mae: 0.4161\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3117 - mae: 0.4029\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3126 - mae: 0.4008\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3101 - mae: 0.3986\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2930 - mae: 0.3920\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2906 - mae: 0.3881\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2982 - mae: 0.3904\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2911 - mae: 0.3859\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2882 - mae: 0.3870\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2558 - mae: 0.3664\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2542 - mae: 0.3632\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2603 - mae: 0.3648\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2566 - mae: 0.3607\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2393 - mae: 0.3520\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2750 - mae: 0.3700\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2362 - mae: 0.3518\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2384 - mae: 0.3504\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2275 - mae: 0.3447\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2260 - mae: 0.3415\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2387 - mae: 0.3459\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2258 - mae: 0.3414\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2158 - mae: 0.3315\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2155 - mae: 0.3338\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2186 - mae: 0.3312\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2209 - mae: 0.3351\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2309 - mae: 0.3362\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2498 - mae: 0.3499\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2453 - mae: 0.3447\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2482 - mae: 0.3507\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2254 - mae: 0.3401\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2445 - mae: 0.3421\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2369 - mae: 0.3373\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.2139 - mae: 0.3236\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2200 - mae: 0.3274\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2088 - mae: 0.3236\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2111 - mae: 0.3246\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2025 - mae: 0.3170\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1977 - mae: 0.3128\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2156 - mae: 0.3236\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2026 - mae: 0.3164\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1889 - mae: 0.3082\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1921 - mae: 0.3087\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2129 - mae: 0.3175\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1921 - mae: 0.3098\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1951 - mae: 0.3104\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1932 - mae: 0.3072\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1885 - mae: 0.3088\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1910 - mae: 0.3093\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2058 - mae: 0.3187\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1920 - mae: 0.3088\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1896 - mae: 0.3047\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1817 - mae: 0.3010\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1792 - mae: 0.3010\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1823 - mae: 0.3033\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1859 - mae: 0.3006\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1857 - mae: 0.3013\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1854 - mae: 0.3044\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1872 - mae: 0.3025\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2002 - mae: 0.3098\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1949 - mae: 0.3107\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2179 - mae: 0.3203\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2117 - mae: 0.3211\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2105 - mae: 0.3181\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1874 - mae: 0.3015\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1823 - mae: 0.3008\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2025 - mae: 0.3115\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1834 - mae: 0.2997\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1861 - mae: 0.3038\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1765 - mae: 0.2939\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1770 - mae: 0.2939\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1871 - mae: 0.3018\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1822 - mae: 0.3007\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1760 - mae: 0.2928\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1842 - mae: 0.2969\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1742 - mae: 0.2936\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1780 - mae: 0.2933\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1852 - mae: 0.3032\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1781 - mae: 0.2963\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1728 - mae: 0.2901\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1696 - mae: 0.2920\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1737 - mae: 0.2931\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1798 - mae: 0.2948\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1778 - mae: 0.2971\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1707 - mae: 0.2894\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1697 - mae: 0.2926\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1742 - mae: 0.2936\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.2015 - mae: 0.3108\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1715 - mae: 0.2929\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1705 - mae: 0.2907\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1797 - mae: 0.2965\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1798 - mae: 0.2956\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1849 - mae: 0.2984\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1817 - mae: 0.2962\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1827 - mae: 0.2989\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1789 - mae: 0.2955\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1734 - mae: 0.2966\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1646 - mae: 0.2870\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1748 - mae: 0.2900\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1746 - mae: 0.2922\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1677 - mae: 0.2855\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1739 - mae: 0.2894\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1738 - mae: 0.2901\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1728 - mae: 0.2924\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1677 - mae: 0.2859\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1774 - mae: 0.2931\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1697 - mae: 0.2901\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1721 - mae: 0.2899\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1688 - mae: 0.2863\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1872 - mae: 0.2989\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1822 - mae: 0.2963\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1795 - mae: 0.2946\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1634 - mae: 0.2857\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1671 - mae: 0.2864\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1669 - mae: 0.2863\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1678 - mae: 0.2849\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1689 - mae: 0.2882\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1624 - mae: 0.2802\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1619 - mae: 0.2824\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1651 - mae: 0.2833\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1658 - mae: 0.2864\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1688 - mae: 0.2880\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1671 - mae: 0.2859\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1680 - mae: 0.2879\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1649 - mae: 0.2836\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1561 - mae: 0.2767\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1656 - mae: 0.2852\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1675 - mae: 0.2864\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1641 - mae: 0.2850\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1740 - mae: 0.2884\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1739 - mae: 0.2857\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1619 - mae: 0.2837\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1611 - mae: 0.2793\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1746 - mae: 0.2900\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1619 - mae: 0.2792\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1676 - mae: 0.2868\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1674 - mae: 0.2840\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1654 - mae: 0.2845\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1778 - mae: 0.2904\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1734 - mae: 0.2876\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1739 - mae: 0.2895\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1590 - mae: 0.2801\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1571 - mae: 0.2776\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1662 - mae: 0.2824\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1591 - mae: 0.2792\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1582 - mae: 0.2794\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1699 - mae: 0.2846\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1709 - mae: 0.2869\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1700 - mae: 0.2892\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1808 - mae: 0.2921\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1936 - mae: 0.3046\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2086 - mae: 0.3089\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1730 - mae: 0.2858\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1755 - mae: 0.2909\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1692 - mae: 0.2894\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1799 - mae: 0.2962\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1646 - mae: 0.2834\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1743 - mae: 0.2952\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1636 - mae: 0.2805\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1577 - mae: 0.2780\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1624 - mae: 0.2809\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1598 - mae: 0.2804\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1620 - mae: 0.2819\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1656 - mae: 0.2815\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1679 - mae: 0.2881\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1642 - mae: 0.2821\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1588 - mae: 0.2798\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1616 - mae: 0.2791\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1706 - mae: 0.2868\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1638 - mae: 0.2836\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1650 - mae: 0.2848\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1701 - mae: 0.2880\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1588 - mae: 0.2824\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1590 - mae: 0.2789\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1612 - mae: 0.2830\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1538 - mae: 0.2763\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1542 - mae: 0.2728\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1543 - mae: 0.2761\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1639 - mae: 0.2814\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1665 - mae: 0.2853\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1645 - mae: 0.2841\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1694 - mae: 0.2869\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1739 - mae: 0.2863\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1684 - mae: 0.2863\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1598 - mae: 0.2780\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1698 - mae: 0.2863\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1594 - mae: 0.2781\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1696 - mae: 0.2858\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1792 - mae: 0.2911\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1594 - mae: 0.2781\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1687 - mae: 0.2880\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1713 - mae: 0.2885\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1665 - mae: 0.2871\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1729 - mae: 0.2882\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1699 - mae: 0.2917\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1697 - mae: 0.2880\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1635 - mae: 0.2826\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1519 - mae: 0.2726\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1568 - mae: 0.2773\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1621 - mae: 0.2798\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1587 - mae: 0.2776\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1563 - mae: 0.2759\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1718 - mae: 0.2860\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1671 - mae: 0.2799\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1659 - mae: 0.2863\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1671 - mae: 0.2835\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1821 - mae: 0.2940\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1628 - mae: 0.2838\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1616 - mae: 0.2833\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1650 - mae: 0.2843\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1657 - mae: 0.2835\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1608 - mae: 0.2791\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1719 - mae: 0.2894\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1632 - mae: 0.2865\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1692 - mae: 0.2837\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1702 - mae: 0.2857\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1679 - mae: 0.2835\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1637 - mae: 0.2771\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1605 - mae: 0.2808\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1742 - mae: 0.2880\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1684 - mae: 0.2859\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1662 - mae: 0.2809\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1670 - mae: 0.2846\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1571 - mae: 0.2778\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.1706 - mae: 0.2859\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1682 - mae: 0.2820\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1559 - mae: 0.2763\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1640 - mae: 0.2805\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1726 - mae: 0.2895\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1636 - mae: 0.2809\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.1565 - mae: 0.2741\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.1703 - mae: 0.2865\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1694 - mae: 0.2810\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1576 - mae: 0.2758\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1701 - mae: 0.2859\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1656 - mae: 0.2810\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.1940 - mae: 0.3013\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1807 - mae: 0.2920\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.1683 - mae: 0.2884\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1524 - mae: 0.2744\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.1653 - mae: 0.2804\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.1616 - mae: 0.2770\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1729 - mae: 0.2859\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1506 - mae: 0.2756\n",
      "损失与精度： [0.15056170523166656, 0.27563539147377014]\n",
      "[[3.979946  3.7013757]\n",
      " [1.7159117 4.830317 ]\n",
      " [5.108709  6.9909286]\n",
      " [9.2901945 8.539221 ]\n",
      " [7.2729735 8.003118 ]\n",
      " [8.985587  8.251951 ]\n",
      " [9.097981  4.6316333]\n",
      " [3.9385202 8.376013 ]\n",
      " [8.948784  1.5882176]\n",
      " [2.252981  2.2642741]]\n",
      "[[3.76 3.77]\n",
      " [1.57 4.63]\n",
      " [5.43 6.77]\n",
      " [9.67 7.94]\n",
      " [7.09 8.28]\n",
      " [8.59 8.24]\n",
      " [9.14 2.22]\n",
      " [3.66 7.91]\n",
      " [8.93 1.86]\n",
      " [2.38 2.02]]\n",
      "MAE指标: 0.2756353968404236\n",
      "MSE指标: 0.15056168751058732\n",
      "RMSE指标: 0.38802279251428945\n",
      "r2指标: 0.9791365168960855\n",
      "ev指标: 0.9791504838038096\n",
      "CPU times: user 6min 8s, sys: 33.2 s, total: 6min 41s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RFID_GRU()\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=333)\n",
    "loss = model.evaluate(X_test, y_test, batch_size=10) # 输出损失和MAE\n",
    "print('损失与精度：', loss)\n",
    "model.save('./models/GRU_2021.h5')\n",
    "\n",
    "pxy = model.predict(X_test)\n",
    "print(pxy[:10])\n",
    "print(y_test[:10])\n",
    "MAE = mean_absolute_error(y_test, pxy)\n",
    "MSE = mean_squared_error(y_test, pxy)\n",
    "r2 = r2_score(y_test, pxy)\n",
    "ev = explained_variance_score(y_test, pxy)\n",
    "print('MAE指标:', MAE)\n",
    "print('MSE指标:', MSE)\n",
    "print('RMSE指标:', math.sqrt(MSE))\n",
    "print('r2指标:', r2)\n",
    "print('ev指标:', ev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f8724",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 使用进化算法调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1d7f0",
   "metadata": {},
   "source": [
    " ### 自定义问题类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba1c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFIDGRU(ea.Problem):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        name = 'RFIDGRU'\n",
    "        M = 1 # 初始化M（目标维数）\n",
    "        maxormins = [-1] # 初始化maxormins（目标最小最大化标记列表，1：最小化该目标；-1：最大化该目标）\n",
    "        Dim = 2 # 初始化Dim（决策变量维数）\n",
    "        varTypes = np.array([0] * Dim) # 初始化varTypes 0-连续\n",
    "        lb = [10, 50] # 决策变量下界\n",
    "        ub = [300, 500] # 决策变量上界\n",
    "        lbin = [1] * Dim # 决策变量下边界（0表示不包含该变量的下边界，1表示包含）\n",
    "        ubin = [1] * Dim # 决策变量上边界（0表示不包含该变量的上边界，1表示包含）\n",
    "        # 调用父类构造方法完成实例化\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "        # 数据设置\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        \n",
    "    # 目标函数，采用多线程加速计算\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen # 得到决策变量矩阵\n",
    "        # print(Vars)\n",
    "        pop.ObjV = np.zeros((pop.sizes, 1)) # 初始化种群个体目标函数值列向量\n",
    "        def subAimFunc(i):\n",
    "            epochs = int(Vars[i, 0])\n",
    "            batch_size = int(Vars[i, 1])\n",
    "            model = RFID_GRU()\n",
    "            model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "            pxy = model.predict(self.X_test)\n",
    "            pop.ObjV[i] = r2_score(self.y_test, pxy) # 最小化MSE作为目标函数\n",
    "        pool = ThreadPool(processes=2) # 设置池的大小\n",
    "        pool.map(subAimFunc, list(range(pop.sizes))) # 散列种群每个个体进行加速计算\n",
    "        \n",
    "        \n",
    "    # 代入优化后的参数对测试集进行检验，计算指标\n",
    "    def test(self, epochs, batch_size):\n",
    "        X02, y02 = load_data('./dataset/location_data02.csv')\n",
    "        model = RFID_GRU()\n",
    "        model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        model.save('./models/GRU_2021.h5')\n",
    "        pxy = model.predict(X02)\n",
    "        MAE = mean_absolute_error(y02, pxy)\n",
    "        MSE = mean_squared_error(y02, pxy)\n",
    "        r2 = r2_score(y02, pxy)\n",
    "        ev = explained_variance_score(y02, pxy)\n",
    "        print('MAE指标:', MAE)\n",
    "        print('MSE指标:', MSE)\n",
    "        print('RMSE指标:', math.sqrt(MSE))\n",
    "        print('r2指标:', r2)\n",
    "        print('ev指标:', ev)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e44c5",
   "metadata": {},
   "source": [
    "### 编写执行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eac9ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 20:38:17.914688: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-24 20:38:18.204977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-24 20:38:18.224203: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "gen|  eval  |    f_opt    |    f_max    |    f_avg    |    f_min    |    f_std    \n",
      "----------------------------------------------------------------------------------\n",
      " 0 |   10   | 9.78002E-01 | 9.78002E-01 | 9.72468E-01 | 9.52237E-01 | 7.26545E-03 \n",
      " 1 |   20   | 9.78040E-01 | 9.78040E-01 | 9.75204E-01 | 9.68645E-01 | 2.98055E-03 \n",
      " 2 |   30   | 9.78449E-01 | 9.78449E-01 | 9.77046E-01 | 9.74051E-01 | 1.34106E-03 \n",
      " 3 |   40   | 9.78449E-01 | 9.78449E-01 | 9.77113E-01 | 9.74051E-01 | 1.30740E-03 \n",
      " 4 |   50   | 9.78449E-01 | 9.78449E-01 | 9.77731E-01 | 9.76747E-01 | 5.05335E-04 \n",
      " 5 |   60   | 9.78449E-01 | 9.78449E-01 | 9.77824E-01 | 9.76747E-01 | 5.32545E-04 \n",
      " 6 |   70   | 9.78449E-01 | 9.78449E-01 | 9.77864E-01 | 9.77080E-01 | 4.59939E-04 \n",
      " 7 |   80   | 9.78449E-01 | 9.78449E-01 | 9.77864E-01 | 9.77080E-01 | 4.59939E-04 \n",
      " 8 |   90   | 9.78449E-01 | 9.78449E-01 | 9.77939E-01 | 9.77080E-01 | 4.61566E-04 \n",
      " 9 |  100   | 9.78665E-01 | 9.78665E-01 | 9.78044E-01 | 9.77080E-01 | 4.16182E-04 \n",
      " 10|  110   | 9.78665E-01 | 9.78665E-01 | 9.78067E-01 | 9.77080E-01 | 4.10452E-04 \n",
      " 11|  120   | 9.78665E-01 | 9.78665E-01 | 9.78119E-01 | 9.77080E-01 | 4.36422E-04 \n",
      " 12|  130   | 9.78665E-01 | 9.78665E-01 | 9.78140E-01 | 9.77080E-01 | 4.33613E-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['SimHei'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13|  140   | 9.78665E-01 | 9.78665E-01 | 9.78184E-01 | 9.77528E-01 | 3.33486E-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 31181 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 32676 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 20010 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 20307 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 24179 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 22343 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 30446 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 26631 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 20540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 26368 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/textpath.py:65: RuntimeWarning: Glyph 20248 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 31181 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32676 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20010 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20307 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24179 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22343 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 30446 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26631 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26368 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20248 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 31181 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32676 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20010 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20307 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24179 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22343 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 30446 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26631 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26368 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20248 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "种群信息导出完毕。\n",
      "用时：10006.560935 秒\n",
      "评价次数：140 次\n",
      "最优的目标函数值为：0.9786652755435872\n",
      "最优的控制变量值为：\n",
      "300.0\n",
      "332.5331808417104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83290/1734558912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\"\"\"=================================检验结果===============================\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestIndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestIndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_83290/2050924276.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/GRU_2021.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mpxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/tjt/anaconda3/envs/tf2-frank/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 100)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"===============================实例化问题对象===========================\"\"\"\n",
    "\n",
    "problem = RFIDGRU(X_train, X_test, y_train, y_test) # 生成问题对象\n",
    "\n",
    "\"\"\"=================================种群设置===============================\"\"\"\n",
    "\n",
    "Encoding = 'RI'       # 编码方式\n",
    "NIND = 10             # 种群规模\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders) # 创建区域描述器\n",
    "population = ea.Population(Encoding, Field, NIND) # 实例化种群对象（此时种群还没被初始化，仅仅是完成种群对象的实例化）\n",
    "\n",
    "\"\"\"===============================算法参数设置=============================\"\"\"\n",
    "\n",
    "myAlgorithm = ea.soea_DE_rand_1_bin_templet(problem, population) # 实例化一个算法模板对象\n",
    "myAlgorithm.MAXGEN = 30 # 最大进化代数\n",
    "myAlgorithm.trappedValue = 1e-6 # “进化停滞”判断阈值\n",
    "myAlgorithm.maxTrappedCount = 10 # 进化停滞计数器最大上限值，如果连续maxTrappedCount代被判定进化陷入停滞，则终止进化\n",
    "myAlgorithm.logTras = 1  # 设置每隔多少代记录日志，若设置成0则表示不记录日志\n",
    "myAlgorithm.verbose = True  # 设置是否打印输出日志信息\n",
    "myAlgorithm.drawing = 1  # 设置绘图方式（0：不绘图；1：绘制结果图；2：绘制目标空间过程动画；3：绘制决策空间过程动画）\n",
    "\n",
    "\"\"\"===========================调用算法模板进行种群进化=======================\"\"\"\n",
    "\n",
    "[BestIndi, population] = myAlgorithm.run()  # 执行算法模板，得到最优个体以及最后一代种群\n",
    "BestIndi.save()  # 把最优个体的信息保存到文件中\n",
    "\n",
    "\"\"\"==================================输出结果=============================\"\"\"\n",
    "\n",
    "print('用时：%f 秒' % myAlgorithm.passTime)\n",
    "print('评价次数：%d 次' % myAlgorithm.evalsNum)\n",
    "if BestIndi.sizes != 0:\n",
    "    print('最优的目标函数值为：%s' % BestIndi.ObjV[0][0])\n",
    "    print('最优的控制变量值为：')\n",
    "    for i in range(BestIndi.Phen.shape[1]):\n",
    "        print(BestIndi.Phen[0, i])\n",
    "else:\n",
    "    print('没找到可行解。')\n",
    "    \n",
    "\"\"\"=================================检验结果===============================\"\"\"\n",
    "\n",
    "problem.test(epochs= int(BestIndi.Phen[0][0]), batch_size= int(BestIndi.Phen[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
